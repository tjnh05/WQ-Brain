checkç‹ã€‘éªŒè¯è¡¨è¾¾å¼æ˜¯å¦æ­£ç¡®çš„è„šæœ¬â€”â€”ä¸ƒåäºŒå˜é»„é‡‘æ­æ¡£
Followed by 30 people

AH18340
GrandMaster consultant
8 days ago Edited
ä½¿ç”¨72å˜æˆ–è€…å¤§æ¨¡å‹ç”Ÿæˆçš„alphaè¡¨è¾¾å¼å¯èƒ½æœ‰è¯­æ³•é”™è¯¯ï¼ŒåŸºäºPLY(Python Lex-Yacc)å†™äº†ç¬¬ä¸€ç‰ˆç”¨äºæ ¡éªŒè¡¨è¾¾å¼æ˜¯å¦æ­£ç¡®

ä½¿ç”¨æ–¹æ³•

1.å®‰è£…åº“ 

pip install ply
2.æ‰§è¡Œè„šæœ¬(è„šæœ¬åæˆ‘å‘½åä¸ºexpression_validator.py)
python expression_validator.py
ä¼šæç¤ºè¾“å…¥jsonæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä½ æŠŠè„šæœ¬æ”¾åˆ°cnhkmcp\untracked/APPç›®å½•ä¸‹ï¼Œ72å˜ç”Ÿæˆçš„alphaåˆšå¥½æ”¾åœ¨Tranformer/output/Alpha_generated_expressions.jsonæ–‡ä»¶ä¸­ï¼Œå›è½¦æ‰§è¡Œå³å¯
è¯·è¾“å…¥è¦æ ¡éªŒçš„è¡¨è¾¾å¼JSONæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šTranformer/output/Alpha_generated_expressions.jsonï¼‰: 
æ‰§è¡Œåä¼šç”Ÿæˆä¸¤ä¸ªæ–‡ä»¶Alpha_generated_expressions_success.json å’ŒAlpha_generated_expressions_error.json å¯¹åº”ç¬¦åˆè§„åˆ™å’Œä¸ç¬¦åˆçš„ã€‚
ç”±äºæ˜¯ç¬¬ä¸€ç‰ˆæœ¬ï¼Œç›®å‰ä¸»è¦æ ¡éªŒè¡¨è¾¾å¼ä¸­æ“ä½œç¬¦çš„ä½¿ç”¨ï¼Œå­—æ®µä¸»è¦æ ¡éªŒæ˜¯ä¸æ˜¯å­—æ¯æ•°å­—ä¸‹åˆ’çº¿ç»„æˆã€‚æœ‰è®¸å¤šä¸å®Œå–„çš„åœ°æ–¹ï¼Œå¦‚æœæœ‰ä¸å¯¹çš„æµ‹è¯•ç”¨ä¾‹æ¬¢è¿åœ¨è¯„è®ºåŒºè¡¥å……
 
ä»£ç ï¼š
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¡¨è¾¾å¼éªŒè¯å™¨ - ä½¿ç”¨æŠ½è±¡è¯­æ³•æ ‘éªŒè¯å­—ç¬¦ä¸²è¡¨è¾¾å¼æ ¼å¼æ˜¯å¦æ­£ç¡®

æœ¬æ¨¡å—å®ç°äº†ä¸€ä¸ªèƒ½å¤Ÿæ£€æµ‹å­—ç¬¦ä¸²è¡¨è¾¾å¼æ ¼å¼æ˜¯å¦æ­£ç¡®çš„ç³»ç»Ÿï¼ŒåŸºäºPLY(Python Lex-Yacc)
æ„å»ºè¯æ³•åˆ†æå™¨å’Œè¯­æ³•åˆ†æå™¨ï¼Œè¯†åˆ«è¡¨è¾¾å¼ä¸­çš„æ“ä½œç¬¦ã€å‡½æ•°å’Œå­—æ®µï¼Œå¹¶éªŒè¯å…¶æ ¼å¼æ­£ç¡®æ€§ã€‚
"""

import re
import sys
import json
import os
from typing import List, Dict, Any, Optional, Tuple

# å°è¯•å¯¼å…¥PLYåº“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æä¾›å®‰è£…æç¤º
try:
    import ply.lex as lex
    import ply.yacc as yacc
except ImportError:
    print("é”™è¯¯: éœ€è¦å®‰è£…PLYåº“ã€‚è¯·è¿è¡Œ 'pip install ply' æ¥å®‰è£…ã€‚")
    sys.exit(1)

# 1. å®šä¹‰æ”¯æŒçš„æ“ä½œç¬¦å’Œå‡½æ•°
supported_functions = {
    # Group ç±»åˆ«å‡½æ•°
    'group_min': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_mean': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression']},
    'group_median': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_max': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_rank': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_vector_proj': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'category']},
    'group_normalize': {'min_args': 2, 'max_args': 5, 'arg_types': ['expression', 'category', 'expression', 'expression', 'expression']},
    'group_extra': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'category']},
    'group_backfill': {'min_args': 3, 'max_args': 4, 'arg_types': ['expression', 'expression', 'expression', 'expression'], 'param_names': ['x', 'cat', 'days', 'std']},
    'group_scale': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_count': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_zscore': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_std_dev': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_sum': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_neutralize': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'category']},
    'group_multi_regression': {'min_args': 4, 'max_args': 9, 'arg_types': ['expression'] * 9},
    'group_cartesian_product': {'min_args': 2, 'max_args': 2, 'arg_types': ['category', 'category']},
    'combo_a': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression']},
    
    # Transformational ç±»åˆ«å‡½æ•°
    'right_tail': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'bucket': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # ç¬¬äºŒä¸ªå‚æ•°å¯ä»¥æ˜¯stringç±»å‹çš„rangeå‚æ•°
    'tail': {'min_args': 1, 'max_args': 4, 'arg_types': ['expression', 'expression', 'expression', 'expression']},
    'left_tail': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'trade_when': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression']},
    'generate_stats': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    
    # Cross Sectional ç±»åˆ«å‡½æ•°
    'winsorize': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'expression'], 'param_names': ['x', 'std']},
    'rank': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'regression_proj': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'vector_neut': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'regression_neut': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'multi_regression': {'min_args': 2, 'max_args': 100, 'arg_types': ['expression'] * 100},  # æ”¯æŒå¤šä¸ªè‡ªå˜é‡
    
    # Time Series ç±»åˆ«å‡½æ•°
    'ts_std_dev': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_mean': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_delay': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_corr': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    'ts_zscore': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_returns': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number'], 'param_names': ['x', 'd', 'mode']},
    'ts_product': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_backfill': {'min_args': 2, 'max_args': 4, 'arg_types': ['expression', 'number', 'number', 'string']},
    'days_from_last_change': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'last_diff_value': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_scale': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number']},
    'ts_entropy': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number'], 'param_names': ['x', 'd', 'buckets']},
    'ts_step': {'min_args': 1, 'max_args': 1, 'arg_types': ['number']},
    'ts_sum': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_co_kurtosis': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    'inst_tvr': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_decay_exp_window': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number'], 'param_names': ['x', 'd', 'factor']},
    'ts_av_diff': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_kurtosis': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_min_max_diff': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number']},
    'ts_arg_max': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_max': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_min_max_cps': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number']},
    'ts_rank': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number']},
    'ts_ir': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_theilsen': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    'hump_decay': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_weighted_decay': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_quantile': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'string']},
    'ts_min': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_count_nans': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_covariance': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    'ts_co_skewness': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    'ts_min_diff': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_decay_linear': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'boolean']},
    'jump_decay': {'min_args': 2, 'max_args': 5, 'arg_types': ['expression', 'number', 'expression', 'number', 'number'], 'param_names': ['x', 'd', 'stddev', 'sensitivity', 'force']},
    'ts_moment': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'number', 'number'], 'param_names': ['x', 'd', 'k']},
    'ts_arg_min': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_regression': {'min_args': 3, 'max_args': 5, 'arg_types': ['expression', 'expression', 'number', 'number', 'number'], 'param_names': ['y', 'x', 'd', 'lag', 'rettype']},
    'ts_skewness': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_max_diff': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'kth_element': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'number', 'number']},
    'hump': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'number'], 'param_names': ['x', 'hump']},
    'ts_median': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_delta': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_poly_regression': {'min_args': 3, 'max_args': 4, 'arg_types': ['expression', 'expression', 'number', 'number']},
    'ts_target_tvr_decay': {'min_args': 1, 'max_args': 4, 'arg_types': ['expression', 'number', 'number', 'number'], 'param_names': ['x', 'lambda_min', 'lambda_max', 'target_tvr']},
    'ts_target_tvr_delta_limit': {'min_args': 2, 'max_args': 5, 'arg_types': ['expression', 'expression', 'number', 'number', 'number']},
    'ts_target_tvr_hump': {'min_args': 1, 'max_args': 4, 'arg_types': ['expression', 'number', 'number', 'number']},
    'ts_delta_limit': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number']},
    
    # Special ç±»åˆ«å‡½æ•°
    'inst_pnl': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'self_corr': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'in': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # æ³¨æ„ï¼šè¿™æ˜¯å…³é”®å­—
    'universe_size': {'min_args': 0, 'max_args': 0, 'arg_types': []},
    
    # Missing functions from operators.py
    'quantile': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression'], 'param_names': ['x', 'driver', 'sigma']},  # quantile(x, driver = gaussian, sigma = 1.0)
    'normalize': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'boolean', 'number']},  # normalize(x, useStd = false, limit = 0.0)
    'zscore': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},  # zscore(x)
    
    # Logical ç±»åˆ«å‡½æ•°
    'or': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # æ³¨æ„ï¼šè¿™æ˜¯å…³é”®å­—
    'and': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # æ³¨æ„ï¼šè¿™æ˜¯å…³é”®å­—
    'not': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},  # æ³¨æ„ï¼šè¿™æ˜¯å…³é”®å­—
    'is_nan': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'is_not_nan': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'less': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'equal': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'greater': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'is_finite': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'if_else': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression']},
    'not_equal': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'less_equal': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'greater_equal': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    
    # Vector ç±»åˆ«å‡½æ•°
    'vec_kurtosis': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_min': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_count': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_sum': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_skewness': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_max': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_avg': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_range': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_choose': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number'], 'param_names': ['x', 'nth']},
    'vec_powersum': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'number'], 'param_names': ['x', 'constant']},
    'vec_stddev': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_percentage': {'min_args': 1, 'max_args': 2, 'arg_types': ['expression', 'number'], 'param_names': ['x', 'percentage']},
    'vec_ir': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'vec_norm': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'ts_percentage': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'number', 'number'], 'param_names': ['x', 'd', 'percentage']},
    'signed_power': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    'ts_product': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number']},
    
    # Additional functions from test cases
    'rank_by_side': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'number', 'number'], 'param_names': ['x', 'rate', 'scale']},
    'log_diff': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'nan_mask': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},
    'ts_partial_corr': {'min_args': 4, 'max_args': 4, 'arg_types': ['expression', 'expression', 'expression', 'number']},
    'ts_triple_corr': {'min_args': 4, 'max_args': 4, 'arg_types': ['expression', 'expression', 'expression', 'number']},
    'clamp': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression'], 'param_names': ['x', 'lower', 'upper']},
    'keep': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'expression', 'number'], 'param_names': ['x', 'condition', 'period']},
    'replace': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression'], 'param_names': ['x', 'target', 'dest']},
    'filter': {'min_args': 3, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression'], 'param_names': ['x', 'h', 't']},
    'one_side': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'string'], 'param_names': ['x', 'side']},
    'scale_down': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'number'], 'param_names': ['x', 'constant']},
    
    # Arithmetic ç±»åˆ«å‡½æ•°
    'add': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'expression', 'boolean']},  # add(x, y, filter=false)
    'multiply': {'min_args': 2, 'max_args': 100, 'arg_types': ['expression'] * 99 + ['boolean'], 'param_names': ['x', 'y', 'filter']},  # multiply(x, y, ..., filter=false)
    'sign': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'subtract': {'min_args': 2, 'max_args': 3, 'arg_types': ['expression', 'expression', 'boolean']},  # subtract(x, y, filter=false)
    'pasteurize': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'log': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'purify': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'arc_tan': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'max': {'min_args': 2, 'max_args': 100, 'arg_types': ['expression'] * 100},  # max(x, y, ...)
    'to_nan': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'expression', 'boolean']},  # to_nan(x, value=0, reverse=false)
    'abs': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'sigmoid': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'divide': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # divide(x, y)
    'min': {'min_args': 2, 'max_args': 100, 'arg_types': ['expression'] * 100},  # min(x, y, ...)
    'tanh': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'nan_out': {'min_args': 1, 'max_args': 3, 'arg_types': ['expression', 'expression', 'expression'], 'param_names': ['x', 'lower', 'upper']},  # nan_out(x, lower=0, upper=0)
    'signed_power': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # signed_power(x, y)
    'inverse': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'round': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'sqrt': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    's_log_1p': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'reverse': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},  # -x
    'power': {'min_args': 2, 'max_args': 2, 'arg_types': ['expression', 'expression']},  # power(x, y)
    'densify': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
    'floor': {'min_args': 1, 'max_args': 1, 'arg_types': ['expression']},
}

# 2. å®šä¹‰groupç±»å‹å­—æ®µ
group_fields = {
    'sector', 'subindustry', 'industry', 'exchange', 'country', 'market'
}

# 3. æœ‰æ•ˆç±»åˆ«é›†åˆ
valid_categories = group_fields

# 4. å­—æ®µå‘½åæ¨¡å¼ - åªæ ¡éªŒå­—æ®µæ˜¯ä¸æ˜¯æ•°å­—å­—æ¯ä¸‹åˆ’çº¿ç»„æˆ
field_patterns = [
    re.compile(r'^[a-zA-Z0-9_]+$'),  # åªå…è®¸æ•°å­—ã€å­—æ¯å’Œä¸‹åˆ’çº¿ç»„æˆçš„å­—æ®µå
]

# 4. æŠ½è±¡è¯­æ³•æ ‘èŠ‚ç‚¹ç±»å‹
class ASTNode:
    """æŠ½è±¡è¯­æ³•æ ‘èŠ‚ç‚¹åŸºç±»"""
    def __init__(self, node_type: str, children: Optional[List['ASTNode']] = None, 
                 value: Optional[Any] = None, line: Optional[int] = None):
        self.node_type = node_type  # 'function', 'operator', 'field', 'number', 'expression'
        self.children = children or []
        self.value = value
        self.line = line
    
    def __str__(self) -> str:
        return f"ASTNode({self.node_type}, {self.value}, line={self.line})"
    
    def __repr__(self) -> str:
        return self.__str__()

class ExpressionValidator:
    """è¡¨è¾¾å¼éªŒè¯å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯æ³•åˆ†æå™¨å’Œè¯­æ³•åˆ†æå™¨"""
        # æ„å»ºè¯æ³•åˆ†æå™¨
        self.lexer = lex.lex(module=self, debug=False)
        # æ„å»ºè¯­æ³•åˆ†æå™¨
        self.parser = yacc.yacc(module=self, debug=False)
        # é”™è¯¯ä¿¡æ¯å­˜å‚¨
        self.errors = []
    
    # è¯æ³•åˆ†æå™¨è§„åˆ™
    tokens = ('FUNCTION', 'FIELD', 'NUMBER', 'LPAREN', 'RPAREN', 
              'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'COMMA', 'CATEGORY',
              'EQUAL', 'ASSIGN', 'IDENTIFIER', 'STRING', 'GREATER', 'LESS', 'GREATEREQUAL', 'LESSEQUAL', 'NOTEQUAL', 'BOOLEAN')
    
    # å¿½ç•¥ç©ºç™½å­—ç¬¦
    t_ignore = ' \t\n'
    
    # æ“ä½œç¬¦ - æ³¨æ„é¡ºåºå¾ˆé‡è¦ï¼Œé•¿çš„æ“ä½œç¬¦è¦æ”¾åœ¨å‰é¢
    t_PLUS = r'\+'
    t_MINUS = r'-'
    t_TIMES = r'\*'
    t_DIVIDE = r'/'
    t_LPAREN = r'\('
    t_RPAREN = r'\)'
    t_COMMA = r','    
    t_EQUAL = r'=='
    t_NOTEQUAL = r'!='
    t_GREATEREQUAL = r'>='
    t_LESSEQUAL = r'<='
    t_GREATER = r'>'
    t_LESS = r'<'
    t_ASSIGN = r'='
    
    # æ•°å­—ï¼ˆæ•´æ•°å’Œæµ®ç‚¹æ•°ï¼‰
    def t_NUMBER(self, t):
        r'\d+\.?\d*'
        if '.' in t.value:
            t.value = float(t.value)
        else:
            t.value = int(t.value)
        return t
    
    # å­—ç¬¦ä¸² - éœ€è¦æ”¾åœ¨æ‰€æœ‰å…¶ä»–æ ‡è¯†ç¬¦è§„åˆ™ä¹‹å‰
    def t_STRING(self, t):
        r"'[^']*'|\"[^\"]*\""
        # å»é™¤å¼•å·
        t.value = t.value[1:-1]
        return t
    
    # å‡½æ•°å’Œå­—æ®µå
    def t_IDENTIFIER(self, t):
        r'[a-zA-Z_][a-zA-Z0-9_]*'
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¸ƒå°”å€¼
        if t.value.lower() in {'true', 'false'}:
            t.type = 'BOOLEAN'
            t.value = t.value.lower()  # è½¬æ¢ä¸ºå°å†™ä»¥ä¿æŒä¸€è‡´æ€§
        else:
            # æŸ¥çœ‹å½“å‰tokenåé¢çš„å­—ç¬¦ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºå‚æ•°åï¼ˆåé¢è·Ÿç€'='ï¼‰
            lexpos = t.lexpos
            next_chars = ''
            if lexpos + len(t.value) < len(t.lexer.lexdata):
                # æŸ¥çœ‹å½“å‰tokenåé¢çš„å­—ç¬¦ï¼Œè·³è¿‡ç©ºæ ¼
                next_pos = lexpos + len(t.value)
                while next_pos < len(t.lexer.lexdata) and t.lexer.lexdata[next_pos].isspace():
                    next_pos += 1
                if next_pos < len(t.lexer.lexdata):
                    next_chars = t.lexer.lexdata[next_pos:next_pos+1]
            
            # å¦‚æœåé¢è·Ÿç€'='ï¼Œåˆ™ä¸ºå‚æ•°å
            if next_chars == '=':
                t.type = 'IDENTIFIER'
            # å¦‚æœåé¢è·Ÿç€'('ï¼Œåˆ™ä¸ºå‡½æ•°å
            elif next_chars == '(':
                t.type = 'FUNCTION'
                t.value = t.value.lower()  # è½¬æ¢ä¸ºå°å†™ä»¥ä¿æŒä¸€è‡´æ€§
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‚æ•°åï¼ˆæ”¯æŒæ›´å¤šå‚æ•°åï¼‰
            elif t.value in {'std', 'k', 'lambda_min', 'lambda_max', 'target_tvr', 'range', 'buckets', 'lag', 'rettype', 'mode', 'nth', 'constant', 'percentage', 'driver', 'sigma', 'rate', 'scale', 'filter', 'lower', 'upper', 'target', 'dest', 'event', 'sensitivity', 'force', 'h', 't', 'period', 'stddev', 'factor', 'k', 'useStd', 'limit', 'gaussian', 'uniform', 'cauchy'}:
                t.type = 'IDENTIFIER'
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‡½æ•°åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
            elif t.value.lower() in supported_functions:
                t.type = 'FUNCTION'
                t.value = t.value.lower()  # è½¬æ¢ä¸ºå°å†™ä»¥ä¿æŒä¸€è‡´æ€§
            # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆç±»åˆ«
            elif t.value in valid_categories:
                t.type = 'CATEGORY'
            # æ£€æŸ¥æ˜¯å¦ä¸ºå­—æ®µå
            elif self._is_valid_field(t.value):
                t.type = 'FIELD'
            else:
                # å…¶ä»–æ ‡è¯†ç¬¦ï¼Œä¿ç•™ä¸ºIDENTIFIERç±»å‹
                t.type = 'IDENTIFIER'
        return t
    
    # è¡Œå·è·Ÿè¸ª
    def t_newline(self, t):
        r'\n+'
        t.lexer.lineno += len(t.value)
    
    # é”™è¯¯å¤„ç†
    def t_error(self, t):
        if t:
            # æ£€æŸ¥æ˜¯å¦ä¸ºéæ³•å­—ç¬¦
            if not re.match(r'[a-zA-Z0-9_\+\-\*/\(\)\,\s=<>!]', t.value[0]):
                # è¿™æ˜¯ä¸€ä¸ªéæ³•å­—ç¬¦
                self.errors.append(f"éæ³•å­—ç¬¦ '{t.value[0]}' (è¡Œ {t.lexer.lineno})")
            else:
                # è¿™æ˜¯ä¸€ä¸ªéæ³•æ ‡è®°
                self.errors.append(f"éæ³•æ ‡è®° '{t.value}' (è¡Œ {t.lexer.lineno})")
            # è·³è¿‡è¿™ä¸ªå­—ç¬¦ï¼Œç»§ç»­å¤„ç†
            t.lexer.skip(1)
        else:
            self.errors.append("è¯æ³•åˆ†æå™¨åˆ°è¾¾æ–‡ä»¶æœ«å°¾")
    
    # è¯­æ³•åˆ†æå™¨è§„åˆ™
    def p_expression(self, p):
        """expression : comparison
                      | expression EQUAL comparison
                      | expression NOTEQUAL comparison
                      | expression GREATER comparison
                      | expression LESS comparison
                      | expression GREATEREQUAL comparison
                      | expression LESSEQUAL comparison"""
        if len(p) == 2:
            p[0] = p[1]
        else:
            p[0] = ASTNode('binop', [p[1], p[3]], {'op': p[2]})
    
    def p_comparison(self, p):
        """comparison : term
                      | comparison PLUS term
                      | comparison MINUS term"""
        if len(p) == 2:
            p[0] = p[1]
        else:
            p[0] = ASTNode('binop', [p[1], p[3]], {'op': p[2]})
    
    def p_term(self, p):
        """term : factor
                | term TIMES factor
                | term DIVIDE factor"""
        if len(p) == 2:
            p[0] = p[1]
        else:
            p[0] = ASTNode('binop', [p[1], p[3]], {'op': p[2]})
    
    def p_factor(self, p):
        """factor : NUMBER
                  | STRING
                  | FIELD
                  | CATEGORY
                  | IDENTIFIER
                  | BOOLEAN
                  | MINUS factor
                  | LPAREN expression RPAREN
                  | function_call"""
        if len(p) == 2:
            # æ•°å­—ã€å­—ç¬¦ä¸²ã€å­—æ®µã€ç±»åˆ«æˆ–æ ‡è¯†ç¬¦
            if p.slice[1].type == 'NUMBER':
                p[0] = ASTNode('number', value=p[1])
            elif p.slice[1].type == 'STRING':
                p[0] = ASTNode('string', value=p[1])
            elif p.slice[1].type == 'FIELD':
                p[0] = ASTNode('field', value=p[1])
            elif p.slice[1].type == 'CATEGORY':
                p[0] = ASTNode('category', value=p[1])
            elif p.slice[1].type == 'BOOLEAN':
                p[0] = ASTNode('boolean', value=p[1])
            elif p.slice[1].type == 'IDENTIFIER':
                p[0] = ASTNode('identifier', value=p[1])
            else:
                p[0] = p[1]
        elif len(p) == 3:
            # ä¸€å…ƒè´Ÿå·
            p[0] = ASTNode('unop', [p[2]], {'op': p[1]})
        elif len(p) == 4:
            # æ‹¬å·è¡¨è¾¾å¼
            p[0] = p[2]
        else:
            # å‡½æ•°è°ƒç”¨
            p[0] = p[1]
    
    def p_function_call(self, p):
        '''function_call : FUNCTION LPAREN args RPAREN'''
        p[0] = ASTNode('function', p[3], p[1])
    
    def p_args(self, p):
        '''args : arg_list
                | empty'''
        if len(p) == 2 and p[1] is not None:
            p[0] = p[1]
        else:
            p[0] = []
    
    def p_arg_list(self, p):
        '''arg_list : arg
                   | arg_list COMMA arg'''
        if len(p) == 2:
            p[0] = [p[1]]
        else:
            p[0] = p[1] + [p[3]]
    
    def p_arg(self, p):
        '''arg : expression
              | IDENTIFIER ASSIGN expression'''
        if len(p) == 2:
            p[0] = {'type': 'positional', 'value': p[1]}
        else:
            p[0] = {'type': 'named', 'name': p[1], 'value': p[3]}
    
    def p_empty(self, p):
        '''empty :'''
        p[0] = None
    
    # è¯­æ³•é”™è¯¯å¤„ç†
    def p_error(self, p):
        if p:
            self.errors.append(f"è¯­æ³•é”™è¯¯åœ¨ä½ç½® {p.lexpos}: éæ³•æ ‡è®° '{p.value}'")
        else:
            self.errors.append("è¯­æ³•é”™è¯¯: è¡¨è¾¾å¼ä¸å®Œæ•´")
    
    def _is_valid_field(self, field_name: str) -> bool:
        """æ£€æŸ¥å­—æ®µåæ˜¯å¦ç¬¦åˆæ¨¡å¼"""
        for pattern in field_patterns:
            if pattern.match(field_name):
                return True
        return False
    
    def validate_function(self, node: ASTNode, is_in_group_arg: bool = False) -> List[str]:
        """éªŒè¯å‡½æ•°è°ƒç”¨çš„å‚æ•°æ•°é‡å’Œç±»å‹"""
        function_name = node.value
        args = node.children
        function_info = supported_functions.get(function_name)
        
        if not function_info:
            return [f"æœªçŸ¥å‡½æ•°: {function_name}"]
        
        errors = []
        
        # æ£€æŸ¥å‚æ•°æ•°é‡
        if len(args) < function_info['min_args']:
            errors.append(f"å‡½æ•° {function_name} éœ€è¦è‡³å°‘ {function_info['min_args']} ä¸ªå‚æ•°ï¼Œä½†åªæä¾›äº† {len(args)}")
        elif len(args) > function_info['max_args']:
            errors.append(f"å‡½æ•° {function_name} æœ€å¤šæ¥å— {function_info['max_args']} ä¸ªå‚æ•°ï¼Œä½†æä¾›äº† {len(args)}")
        
        # å¤„ç†å‚æ•°éªŒè¯
        # è·Ÿè¸ªå·²ä½¿ç”¨çš„ä½ç½®å‚æ•°ç´¢å¼•
        positional_index = 0
        
        # å¯¹äºæ‰€æœ‰å‡½æ•°ï¼Œæ”¯æŒå‘½åå‚æ•°
        for arg in args:
            if isinstance(arg, dict):
                if arg['type'] == 'named':
                    # å‘½åå‚æ•°
                    if 'param_names' in function_info and arg['name'] in function_info['param_names']:
                        # æŸ¥æ‰¾å‚æ•°åœ¨param_namesä¸­çš„ç´¢å¼•
                        param_index = function_info['param_names'].index(arg['name'])
                        if param_index < len(function_info['arg_types']):
                            expected_type = function_info['arg_types'][param_index]
                            arg_errors = self._validate_arg_type(arg['value'], expected_type, param_index, function_name, is_in_group_arg)
                            errors.extend(arg_errors)
                    # å¯¹äºwinsorizeå‡½æ•°ï¼Œæ”¯æŒstdå’Œclipå‚æ•°
                    elif function_name == 'winsorize' and arg['name'] in ['std', 'clip']:
                        arg_errors = self._validate_arg_type(arg['value'], 'number', 0, function_name, is_in_group_arg)
                        errors.extend(arg_errors)
                    # å¯¹äºbucketå‡½æ•°ï¼Œæ”¯æŒ'range'å’Œ'buckets'å‚æ•°
                    elif function_name == 'bucket' and arg['name'] in ['range', 'buckets']:
                        # rangeå’Œbucketså‚æ•°åº”è¯¥æ˜¯stringç±»å‹
                        arg_errors = self._validate_arg_type(arg['value'], 'string', 1, function_name, is_in_group_arg)
                        errors.extend(arg_errors)
                    else:
                        errors.append(f"å‡½æ•° {function_name} ä¸å­˜åœ¨å‚æ•° '{arg['name']}'")
                elif arg['type'] == 'positional':
                    # ä½ç½®å‚æ•°ï¼ˆå­—å…¸å½¢å¼ï¼‰
                    # å¯¹äºwinsorizeå‡½æ•°ï¼Œç¬¬äºŒä¸ªå‚æ•°å¿…é¡»æ˜¯å‘½åå‚æ•°
                    if function_name == 'winsorize' and positional_index == 1:
                        errors.append(f"å‡½æ•° {function_name} çš„ç¬¬äºŒä¸ªå‚æ•°å¿…é¡»ä½¿ç”¨å‘½åå‚æ•° 'std='")
                    # å¯¹äºts_momentå‡½æ•°ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°å¿…é¡»æ˜¯å‘½åå‚æ•°
                    elif function_name == 'ts_moment' and positional_index == 2:
                        errors.append(f"å‡½æ•° {function_name} çš„ç¬¬ä¸‰ä¸ªå‚æ•°å¿…é¡»ä½¿ç”¨å‘½åå‚æ•° 'k='")
                    else:
                        # éªŒè¯ä½ç½®å‚æ•°çš„ç±»å‹
                        if positional_index < len(function_info['arg_types']):
                            expected_type = function_info['arg_types'][positional_index]
                            arg_errors = self._validate_arg_type(arg['value'], expected_type, positional_index, function_name, is_in_group_arg)
                            errors.extend(arg_errors)
                    positional_index += 1
                else:
                    # å…¶ä»–å­—å…¸ç±»å‹å‚æ•°
                    errors.append(f"å‚æ•° {positional_index+1} æ ¼å¼é”™è¯¯")
                    positional_index += 1
            else:
                # ä½ç½®å‚æ•°ï¼ˆç›´æ¥ASTNodeå½¢å¼ï¼‰
                # å¯¹äºwinsorizeå‡½æ•°ï¼Œç¬¬äºŒä¸ªå‚æ•°å¿…é¡»æ˜¯å‘½åå‚æ•°
                if function_name == 'winsorize' and positional_index == 1:
                    errors.append(f"å‡½æ•° {function_name} çš„ç¬¬äºŒä¸ªå‚æ•°å¿…é¡»ä½¿ç”¨å‘½åå‚æ•° 'std='")
                # å¯¹äºts_momentå‡½æ•°ï¼Œç¬¬ä¸‰ä¸ªå‚æ•°å¿…é¡»æ˜¯å‘½åå‚æ•°
                elif function_name == 'ts_moment' and positional_index == 2:
                    errors.append(f"å‡½æ•° {function_name} çš„ç¬¬ä¸‰ä¸ªå‚æ•°å¿…é¡»ä½¿ç”¨å‘½åå‚æ•° 'k='")
                else:
                    # éªŒè¯ä½ç½®å‚æ•°çš„ç±»å‹
                    if positional_index < len(function_info['arg_types']):
                        expected_type = function_info['arg_types'][positional_index]
                        arg_errors = self._validate_arg_type(arg, expected_type, positional_index, function_name, is_in_group_arg)
                        errors.extend(arg_errors)
                positional_index += 1
        
        return errors
    
    def _validate_arg_type(self, arg: ASTNode, expected_type: str, arg_index: int, function_name: str, is_in_group_arg: bool = False) -> List[str]:
        """éªŒè¯å‚æ•°ç±»å‹æ˜¯å¦ç¬¦åˆé¢„æœŸ"""
        errors = []
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯groupç±»å‹å­—æ®µï¼Œå¦‚æœæ˜¯åˆ™åªèƒ½ç”¨äºGroupç±»å‹å‡½æ•°
        # ä½†æ˜¯å¦‚æœå½“å‰å‡½æ•°æ˜¯group_xxxæˆ–åœ¨groupå‡½æ•°çš„å‚æ•°é“¾ä¸­ï¼Œåˆ™å…è®¸ä½¿ç”¨
        if arg.node_type == 'category' and arg.value in group_fields:
            if not (function_name.startswith('group_') or is_in_group_arg):
                errors.append(f"Groupç±»å‹å­—æ®µ '{arg.value}' åªèƒ½ç”¨äºGroupç±»å‹å‡½æ•°çš„å‚æ•°ä¸­")
        
        # ç„¶åéªŒè¯å‚æ•°ç±»å‹æ˜¯å¦ç¬¦åˆé¢„æœŸ
        if expected_type == 'expression':
            # è¡¨è¾¾å¼å¯ä»¥æ˜¯ä»»ä½•æœ‰æ•ˆçš„ASTèŠ‚ç‚¹
            pass
        elif expected_type == 'number':
            if arg.node_type != 'number':
                errors.append(f"å‚æ•° {arg_index+1} åº”è¯¥æ˜¯ä¸€ä¸ªæ•°å­—ï¼Œä½†å¾—åˆ° {arg.node_type}")
        elif expected_type == 'boolean':
            # å¸ƒå°”å€¼å¯ä»¥æ˜¯æ•°å­—ï¼ˆ0/1ï¼‰
            if arg.node_type != 'number':
                errors.append(f"å‚æ•° {arg_index+1} åº”è¯¥æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼ï¼ˆ0/1ï¼‰ï¼Œä½†å¾—åˆ° {arg.node_type}")
        elif expected_type == 'field':
            if arg.node_type != 'field' and arg.node_type != 'category':
                # å…è®¸fieldæˆ–categoryä½œä¸ºå­—æ®µå‚æ•°
                errors.append(f"å‚æ•° {arg_index+1} åº”è¯¥æ˜¯ä¸€ä¸ªå­—æ®µï¼Œä½†å¾—åˆ° {arg.node_type}")
            elif arg.node_type == 'field' and not self._is_valid_field(arg.value):
                errors.append(f"æ— æ•ˆçš„å­—æ®µå: {arg.value}")
        elif expected_type == 'category':
            if not function_name.startswith('group_'):
                # égroupå‡½æ•°çš„categoryå‚æ•°å¿…é¡»æ˜¯categoryç±»å‹ä¸”åœ¨valid_categoriesä¸­
                if arg.node_type != 'category':
                    errors.append(f"å‚æ•° {arg_index+1} åº”è¯¥æ˜¯ä¸€ä¸ªç±»åˆ«ï¼Œä½†å¾—åˆ° {arg.node_type}")
                elif arg.value not in valid_categories:
                    errors.append(f"æ— æ•ˆçš„ç±»åˆ«: {arg.value}")
            # groupå‡½æ•°çš„categoryå‚æ•°å¯ä»¥æ˜¯ä»»ä½•ç±»å‹ï¼ˆfieldã€categoryç­‰ï¼‰ï¼Œä¸è¿›è¡Œç±»å‹æ ¡éªŒ
        
        return errors
    
    def validate_ast(self, ast: Optional[ASTNode], is_in_group_arg: bool = False) -> List[str]:
        """é€’å½’éªŒè¯æŠ½è±¡è¯­æ³•æ ‘"""
        if not ast:
            return ["æ— æ³•è§£æè¡¨è¾¾å¼"]
        
        errors = []
        
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹è¿›è¡ŒéªŒè¯
        if ast.node_type == 'function':
            # æ£€æŸ¥å½“å‰å‡½æ•°æ˜¯å¦æ˜¯groupå‡½æ•°
            is_group_function = ast.value.startswith('group_')
            # ç¡®å®šå½“å‰æ˜¯å¦åœ¨groupå‡½æ•°çš„å‚æ•°é“¾ä¸­
            current_in_group_arg = is_in_group_arg or is_group_function
            # éªŒè¯å‡½æ•°
            function_errors = self.validate_function(ast, current_in_group_arg)
            errors.extend(function_errors)
            
            # é€’å½’éªŒè¯å­èŠ‚ç‚¹æ—¶ä½¿ç”¨current_in_group_arg
            for child in ast.children:
                if isinstance(child, dict):
                    # å‘½åå‚æ•°ï¼ŒéªŒè¯å…¶å€¼
                    if 'value' in child and hasattr(child['value'], 'node_type'):
                        child_errors = self.validate_ast(child['value'], current_in_group_arg)
                        errors.extend(child_errors)
                elif hasattr(child, 'node_type'):
                    child_errors = self.validate_ast(child, current_in_group_arg)
                    errors.extend(child_errors)
        elif ast.node_type in ['unop', 'binop']:
            # å¯¹æ“ä½œç¬¦çš„å­èŠ‚ç‚¹è¿›è¡ŒéªŒè¯
            for child in ast.children:
                if hasattr(child, 'node_type'):
                    child_errors = self.validate_ast(child, is_in_group_arg)
                    errors.extend(child_errors)
        elif ast.node_type == 'field':
            # éªŒè¯å­—æ®µå
            if not self._is_valid_field(ast.value):
                errors.append(f"æ— æ•ˆçš„å­—æ®µå: {ast.value}")
        else:
            # é€’å½’éªŒè¯å­èŠ‚ç‚¹
            for child in ast.children:
                if isinstance(child, dict):
                    # å‘½åå‚æ•°ï¼ŒéªŒè¯å…¶å€¼
                    if 'value' in child and hasattr(child['value'], 'node_type'):
                        child_errors = self.validate_ast(child['value'], is_in_group_arg)
                        errors.extend(child_errors)
                elif hasattr(child, 'node_type'):
                    child_errors = self.validate_ast(child, is_in_group_arg)
                    errors.extend(child_errors)
        
        return errors
    
    def _process_semicolon_expression(self, expression: str) -> Tuple[bool, str]:
        """å¤„ç†å¸¦æœ‰åˆ†å·çš„è¡¨è¾¾å¼ï¼Œå°†å…¶è½¬æ¢ä¸ºä¸å¸¦åˆ†å·çš„ç®€åŒ–å½¢å¼
        
        Args:
            expression: è¦å¤„ç†çš„è¡¨è¾¾å¼å­—ç¬¦ä¸²
            
        Returns:
            Tuple[bool, str]: (æ˜¯å¦æˆåŠŸ, è½¬æ¢åçš„è¡¨è¾¾å¼æˆ–é”™è¯¯ä¿¡æ¯)
        """
        # æ£€æŸ¥è¡¨è¾¾å¼æ˜¯å¦ä»¥åˆ†å·ç»“å°¾
        if expression.strip().endswith(';'):
            return False, "è¡¨è¾¾å¼ä¸èƒ½ä»¥åˆ†å·ç»“å°¾"
        
        # åˆ†å‰²è¡¨è¾¾å¼ä¸ºè¯­å¥åˆ—è¡¨
        statements = [stmt.strip() for stmt in expression.split(';') if stmt.strip()]
        if not statements:
            return False, "è¡¨è¾¾å¼ä¸èƒ½ä¸ºç©º"
        
        # å­˜å‚¨å˜é‡èµ‹å€¼
        variables = {}
        
        # å¤„ç†æ¯ä¸ªèµ‹å€¼è¯­å¥ï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
        for i, stmt in enumerate(statements[:-1]):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«èµ‹å€¼ç¬¦å·
            if '=' not in stmt:
                return False, f"ç¬¬{i+1}ä¸ªè¯­å¥å¿…é¡»æ˜¯èµ‹å€¼è¯­å¥ï¼ˆä½¿ç”¨=ç¬¦å·ï¼‰"
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ¯”è¾ƒæ“ä½œç¬¦ï¼ˆ==, !=, <=, >=ï¼‰
            if any(op in stmt for op in ['==', '!=', '<=', '>=']):
                # å¦‚æœåŒ…å«æ¯”è¾ƒæ“ä½œç¬¦ï¼Œéœ€è¦ç¡®è®¤æ˜¯å¦æœ‰èµ‹å€¼ç¬¦å·
                # ä½¿ç”¨ä¸´æ—¶æ›¿æ¢æ³•ï¼šå°†æ¯”è¾ƒæ“ä½œç¬¦æ›¿æ¢ä¸ºä¸´æ—¶æ ‡è®°ï¼Œå†æ£€æŸ¥æ˜¯å¦è¿˜æœ‰=
                temp_stmt = stmt
                for op in ['==', '!=', '<=', '>=']:
                    temp_stmt = temp_stmt.replace(op, '---')
                
                if '=' not in temp_stmt:
                    return False, f"ç¬¬{i+1}ä¸ªè¯­å¥å¿…é¡»æ˜¯èµ‹å€¼è¯­å¥ï¼Œä¸èƒ½åªæ˜¯æ¯”è¾ƒè¡¨è¾¾å¼"
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª=ç¬¦å·ï¼ˆä¸æ˜¯æ¯”è¾ƒæ“ä½œç¬¦çš„ä¸€éƒ¨åˆ†ï¼‰
            # å…ˆå°†æ¯”è¾ƒæ“ä½œç¬¦æ›¿æ¢ä¸ºä¸´æ—¶æ ‡è®°ï¼Œå†æ‰¾=
            temp_stmt = stmt
            for op in ['==', '!=', '<=', '>=']:
                temp_stmt = temp_stmt.replace(op, '---')
            
            if '=' not in temp_stmt:
                return False, f"ç¬¬{i+1}ä¸ªè¯­å¥å¿…é¡»æ˜¯èµ‹å€¼è¯­å¥ï¼ˆä½¿ç”¨=ç¬¦å·ï¼‰"
            
            # æ‰¾åˆ°å®é™…çš„=ä½ç½®
            equals_pos = temp_stmt.index('=')
            
            # åœ¨åŸå§‹è¯­å¥ä¸­æ‰¾åˆ°å¯¹åº”ä½ç½®
            real_equals_pos = 0
            temp_count = 0
            for char in stmt:
                if temp_count == equals_pos:
                    break
                if char in '!<>':
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¯”è¾ƒæ“ä½œç¬¦çš„ä¸€éƒ¨åˆ†
                    if real_equals_pos + 1 < len(stmt) and stmt[real_equals_pos + 1] == '=':
                        # æ˜¯æ¯”è¾ƒæ“ä½œç¬¦ï¼Œè·³è¿‡ä¸¤ä¸ªå­—ç¬¦
                        real_equals_pos += 2
                        temp_count += 3  # å› ä¸ºæ›¿æ¢æˆäº†ä¸‰ä¸ªå­—ç¬¦çš„---
                    else:
                        real_equals_pos += 1
                        temp_count += 1
                else:
                    real_equals_pos += 1
                    temp_count += 1
            
            # åˆ†å‰²å˜é‡åå’Œå€¼
            var_name = stmt[:real_equals_pos].strip()
            var_value = stmt[real_equals_pos + 1:].strip()
            
            # æ£€æŸ¥å˜é‡åæ˜¯å¦æœ‰æ•ˆ
            if not re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', var_name):
                return False, f"ç¬¬{i+1}ä¸ªè¯­å¥çš„å˜é‡å'{var_name}'æ— æ•ˆï¼Œåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿ï¼Œä¸”ä¸èƒ½ä»¥æ•°å­—å¼€å¤´"
            
            var_name_lower = var_name.lower()  # å˜é‡åä¸åŒºåˆ†å¤§å°å†™
            
            # æ£€æŸ¥å˜é‡åæ˜¯å¦åœ¨åç»­è¡¨è¾¾å¼ä¸­ä½¿ç”¨
            # è¿™é‡Œä¸éœ€è¦ï¼Œå› ä¸ºåé¢çš„è¡¨è¾¾å¼ä¼šæ£€æŸ¥
            
            # æ£€æŸ¥å˜é‡å€¼ä¸­ä½¿ç”¨çš„å˜é‡æ˜¯å¦å·²ç»å®šä¹‰
            # ç®€å•æ£€æŸ¥ï¼šæå–æ‰€æœ‰å¯èƒ½çš„å˜é‡å
            used_vars = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', var_value)
            for used_var in used_vars:
                used_var_lower = used_var.lower()
                if used_var_lower not in variables:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°å
                    if used_var not in supported_functions:
                        # å¯¹äºå•ä¸ªå­—æ¯æˆ–ç®€å•å•è¯ï¼Œä¸è‡ªåŠ¨è§†ä¸ºå­—æ®µåï¼Œè¦æ±‚å…ˆå®šä¹‰
                        if len(used_var) <= 2:
                            return False, f"ç¬¬{i+1}ä¸ªè¯­å¥ä¸­ä½¿ç”¨çš„å˜é‡'{used_var}'æœªåœ¨ä¹‹å‰å®šä¹‰"
                        # å¯¹äºè¾ƒé•¿çš„å­—æ®µåï¼Œä»ç„¶å…è®¸ä½œä¸ºå­—æ®µå
                        elif not self._is_valid_field(used_var):
                            return False, f"ç¬¬{i+1}ä¸ªè¯­å¥ä¸­ä½¿ç”¨çš„å˜é‡'{used_var}'æœªåœ¨ä¹‹å‰å®šä¹‰"
            
            # å°†ä¹‹å‰å®šä¹‰çš„å˜é‡æ›¿æ¢åˆ°å½“å‰å€¼ä¸­
            for existing_var, existing_val in variables.items():
                # ä½¿ç”¨å•è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…æ›¿æ¢åˆ°å…¶ä»–å•è¯çš„ä¸€éƒ¨åˆ†
                var_value = re.sub(rf'\b{existing_var}\b', existing_val, var_value)
            
            # å­˜å‚¨å˜é‡
            variables[var_name_lower] = var_value
        
        # å¤„ç†æœ€åä¸€ä¸ªè¯­å¥ï¼ˆå®é™…çš„è¡¨è¾¾å¼ï¼‰
        final_stmt = statements[-1]
        
        # æ£€æŸ¥æœ€åä¸€ä¸ªè¯­å¥æ˜¯å¦æ˜¯èµ‹å€¼è¯­å¥
        if '=' in final_stmt:
            # æ›¿æ¢æ¯”è¾ƒæ“ä½œç¬¦ä¸ºä¸´æ—¶æ ‡è®°ï¼Œç„¶åæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å•ç‹¬çš„=
            temp_stmt = final_stmt
            for op in ['==', '!=', '<=', '>=']:
                temp_stmt = temp_stmt.replace(op, '---')
            
            if '=' in temp_stmt:
                return False, "æœ€åä¸€ä¸ªè¯­å¥ä¸èƒ½æ˜¯èµ‹å€¼è¯­å¥"
        
        # æ£€æŸ¥æœ€åä¸€ä¸ªè¯­å¥ä¸­ä½¿ç”¨çš„å˜é‡æ˜¯å¦å·²ç»å®šä¹‰
        used_vars = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', final_stmt)
        for used_var in used_vars:
            used_var_lower = used_var.lower()
            if used_var_lower not in variables:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°å
                if used_var not in supported_functions:
                    # åœ¨åˆ†å·è¡¨è¾¾å¼ä¸­ï¼Œæ‰€æœ‰éå‡½æ•°åçš„æ ‡è¯†ç¬¦éƒ½å¿…é¡»æ˜¯å˜é‡ï¼Œå¿…é¡»åœ¨ä¹‹å‰å®šä¹‰
                    return False, f"æœ€åä¸€ä¸ªè¯­å¥ä¸­ä½¿ç”¨çš„å˜é‡'{used_var}'æœªåœ¨ä¹‹å‰å®šä¹‰"
        
        # å°†å˜é‡æ›¿æ¢åˆ°æœ€åä¸€ä¸ªè¡¨è¾¾å¼ä¸­
        final_expr = final_stmt
        for var_name, var_value in variables.items():
            final_expr = re.sub(rf'\b{var_name}\b', var_value, final_expr)
        
        return True, final_expr
    
    def check_expression(self, expression: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥è¡¨è¾¾å¼æ ¼å¼æ˜¯å¦æ­£ç¡®
        
        Args:
            expression: è¦éªŒè¯çš„è¡¨è¾¾å¼å­—ç¬¦ä¸²
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        # é‡ç½®é”™è¯¯åˆ—è¡¨
        self.errors = []
        
        try:
            expression = expression.strip()
            if not expression:
                return {
                    'valid': False,
                    'errors': ['è¡¨è¾¾å¼ä¸èƒ½ä¸ºç©º'],
                    'tokens': [],
                    'ast': None
                }
            
            # å¤„ç†å¸¦æœ‰åˆ†å·çš„è¡¨è¾¾å¼
            if ';' in expression:
                success, result = self._process_semicolon_expression(expression)
                if not success:
                    return {
                        'valid': False,
                        'errors': [result],
                        'tokens': [],
                        'ast': None
                    }
                expression = result
            
            # é‡ç½®è¯æ³•åˆ†æå™¨çš„è¡Œå·
            self.lexer.lineno = 1
            
            # è¯æ³•åˆ†æï¼ˆç”¨äºè°ƒè¯•ï¼‰
            self.lexer.input(expression)
            tokens = []
            # è°ƒè¯•ï¼šæ‰“å°è¯†åˆ«çš„æ ‡è®°
            print(f"\nè°ƒè¯• - è¡¨è¾¾å¼: {expression}")
            print("è¯†åˆ«çš„æ ‡è®°:")
            for token in self.lexer:
                print(f"  - ç±»å‹: {token.type}, å€¼: '{token.value}', ä½ç½®: {token.lexpos}")
                tokens.append(token)
            
            # é‡æ–°è®¾ç½®è¯æ³•åˆ†æå™¨çš„è¾“å…¥ï¼Œä»¥ä¾¿è¯­æ³•åˆ†æå™¨ä½¿ç”¨
            self.lexer.input(expression)
            self.lexer.lineno = 1
            
            # è¯­æ³•åˆ†æ
            ast = self.parser.parse(expression, lexer=self.lexer)
            
            # éªŒè¯AST
            validation_errors = self.validate_ast(ast)
            
            # åˆå¹¶æ‰€æœ‰é”™è¯¯
            all_errors = self.errors + validation_errors
            
            # æ£€æŸ¥æ‹¬å·æ˜¯å¦åŒ¹é…
            bracket_count = 0
            for char in expression:
                if char == '(':
                    bracket_count += 1
                elif char == ')':
                    bracket_count -= 1
                if bracket_count < 0:
                    all_errors.append("æ‹¬å·ä¸åŒ¹é…: å³æ‹¬å·è¿‡å¤š")
                    break
            if bracket_count > 0:
                all_errors.append("æ‹¬å·ä¸åŒ¹é…: å·¦æ‹¬å·è¿‡å¤š")
            
            return {
                'valid': len(all_errors) == 0,
                'errors': all_errors,
                'tokens': tokens,
                'ast': ast
            }
        except Exception as e:
            return {
                'valid': False,
                'errors': [f"è§£æé”™è¯¯: {str(e)}"],
                'tokens': [],
                'ast': None
            }

def main():
    """ä¸»å‡½æ•° - ç”¨äºéªŒè¯è¡¨è¾¾å¼å¹¶è¾“å‡ºç»“æœåˆ°JSONæ–‡ä»¶"""
    validator = ExpressionValidator()
    
    # è·å–ç”¨æˆ·è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤è·¯å¾„ä¸ºå½“å‰è·¯å¾„ä¸‹çš„Tranformer/output/Alpha_generated_expressions.json
    default_path = os.path.join("Tranformer", "output", "Alpha_generated_expressions.json")
    input_path = input(f"è¯·è¾“å…¥è¦æ ¡éªŒçš„è¡¨è¾¾å¼JSONæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼š{default_path}ï¼‰: ").strip()
    
    if not input_path:
        input_path = default_path
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"é”™è¯¯: æ–‡ä»¶ {input_path} ä¸å­˜åœ¨")
        return
    
    # è¯»å–JSONæ–‡ä»¶
    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            expressions_data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"é”™è¯¯: JSONæ–‡ä»¶è§£æå¤±è´¥ - {e}")
        return
    
    # æå–è¡¨è¾¾å¼åˆ—è¡¨
    # å‡è®¾JSONæ–‡ä»¶ç»“æ„ä¸º {"expressions": ["expr1", "expr2", ...]} æˆ–ç›´æ¥æ˜¯ ["expr1", "expr2", ...]
    if isinstance(expressions_data, dict) and "expressions" in expressions_data:
        expressions = expressions_data["expressions"]
    elif isinstance(expressions_data, list):
        expressions = expressions_data
    else:
        print("é”™è¯¯: JSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œéœ€è¦åŒ…å«è¡¨è¾¾å¼åˆ—è¡¨")
        return
    
    # éªŒè¯è¡¨è¾¾å¼
    valid_expressions = []
    invalid_expressions = []
    
    print(f"å¼€å§‹éªŒè¯ {len(expressions)} ä¸ªè¡¨è¾¾å¼...")
    for i, expr in enumerate(expressions, 1):
        if i % 10 == 0:
            print(f"å·²éªŒè¯ {i}/{len(expressions)} ä¸ªè¡¨è¾¾å¼")
            
        result = validator.check_expression(expr)
        if result["valid"]:
            valid_expressions.append(expr)
        else:
            invalid_expressions.append({"expression": expr, "errors": result["errors"]})
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    base_name = os.path.basename(input_path)
    name, ext = os.path.splitext(base_name)
    output_dir = os.path.dirname(input_path)
    
    valid_output_path = os.path.join(output_dir, f"{name}_success{ext}")
    invalid_output_path = os.path.join(output_dir, f"{name}_error{ext}")
    
    # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
    print(f"\néªŒè¯å®Œæˆï¼")
    print(f"æœ‰æ•ˆè¡¨è¾¾å¼: {len(valid_expressions)}")
    print(f"æ— æ•ˆè¡¨è¾¾å¼: {len(invalid_expressions)}")
    
    # ä¿å­˜æœ‰æ•ˆè¡¨è¾¾å¼
    try:
        with open(valid_output_path, 'w', encoding='utf-8') as f:
            json.dump(valid_expressions, f, ensure_ascii=False, indent=2)
        print(f"æœ‰æ•ˆè¡¨è¾¾å¼å·²ä¿å­˜åˆ°: {valid_output_path}")
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜æœ‰æ•ˆè¡¨è¾¾å¼å¤±è´¥ - {e}")
    
    # ä¿å­˜æ— æ•ˆè¡¨è¾¾å¼
    try:
        with open(invalid_output_path, 'w', encoding='utf-8') as f:
            json.dump(invalid_expressions, f, ensure_ascii=False, indent=2)
        print(f"æ— æ•ˆè¡¨è¾¾å¼å·²ä¿å­˜åˆ°: {invalid_output_path}")
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜æ— æ•ˆè¡¨è¾¾å¼å¤±è´¥ - {e}")

if __name__ == "__main__":
    main()

31
Comments
12 commentsSort by 

LL87164
Master consultant
8 days ago
å®æµ‹å¥½ç”¨ï¼

ç‚¹èµğŸ‘


1


LW67640
Gold consultant
8 days ago
å¤§ä½¬çš„åŠ¨ä½œå¥½å¿«ï¼Œæ˜¨æ™šæˆ‘è¿˜æƒ³æ€ä¹ˆå¼„ï¼Œä»Šå¤©å°±çœ‹åˆ°äº†å¸–å­ã€‚

è¿è¡Œä¸€æ¬¡é€šè¿‡ï¼Œéå¸¸æœ‰å¯å‘ã€‚

-----------------------------------------------------------------------------------------------------------

å¤§æ¨¡å‹çš„æ—¶ä»£ä¸çŸ¥ä¸è§‰å°±æ¥äº†ã€‚ã€‚ã€‚ç”¨ä¸­å­¦ã€‚ã€‚ã€‚


0


ZX59167
Gold consultant
7 days ago
ä½ å¥½ è¯·é—®å®˜æ–¹é‚£ä¸ªä»£ç åœ¨å“ªè·å–å—


0


WF69827
Gold consultant
7 days ago
èƒ½å¦æ£€éªŒå¤„è¿˜æ²¡æœ‰æƒé™ä½¿ç”¨çš„è¿ç®—ç¬¦ï¼Ÿ


1


HJ31437
Gold consultant
7 days ago
æ„Ÿè°¢å¤§ä½¬çš„æ ¡éªŒï¼Œè§£å†³äº†ä¸€äº›è¡¨è¾¾å¼é”™è¯¯ï¼Œå¯ä»¥å‡å°‘æ— ç”¨çš„å›æµ‹


1


GZ60647
Gold consultant
7 days ago
è¯•ç”¨äº†ä¸‹ï¼Œå¾ˆä¸é”™ï¼Œæ‰¾å‡ºäº†é”™è¯¯ã€‚ç»™å¤§ä½¬ç‚¹èµã€‚


1


WL13229
7 days ago
WF69827

ä¼¼ä¹å¯ä»¥è®©AIæ”¹ä¸€ä¸‹è¿™ä¸ªä»£ç 


1


AH18340
GrandMaster consultant
7 days ago
@WF69827 ä½ å¯ä»¥åœ¨ä»£ç é‡Œé¢

supported_functions=
è¿™é‡Œå®šä¹‰è¿ç®—ç¬¦æŠŠä½ æ²¡æœ‰è¿ç®—ç¬¦åˆ æ‰


1


XG98059
Gold consultant
7 days ago
çœŸæ˜¯å¦‚ç¥å…µå¤©åŠ©å•Šã€‚


0


SL52857
Master consultant
6 days ago
ä¸€ç›´è¢«aiç”Ÿæˆçš„è¡¨è¾¾å¼é‡Œé”™è¯¯å¤ªå¤šè€Œå›°æ‰°ï¼Œå¤§ä½¬çš„ä»£ç å¾ˆå¼ºğŸ‘


0


HZ99685
Gold consultant
5 days ago
æ–°appé‡Œå·²ç»é›†æˆäº†å§


0


HL81191
Gold consultant
2 days ago
å¾ˆæ£’ï¼Œè¿™ä¸‹å¯ä»¥æ›´é«˜æ•ˆçš„å›æµ‹äº†ã€‚æœ‰æ—¶å€™å¤§æ¨¡å‹ä¼šç”Ÿæˆé”™è¯¯çš„è¡¨è¾¾å¼å¯¼è‡´å›æµ‹ä¸æˆåŠŸï¼Œæˆ‘ä¹‹å‰å¯åŠ¨åå°±æ²¡çœ‹è¿è¡Œï¼Œèµ·åºŠå‘ç°å…¨æ˜¯è“å­—url,æµªè´¹äº†æˆ‘ä¸€æ™šä¸Šçš„å›æµ‹æ—¶é—´


0


Didn't find what you were looking for?
